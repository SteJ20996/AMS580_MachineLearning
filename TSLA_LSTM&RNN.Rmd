---
title: "ex.TSLA as example data set, using Long-Short-Term Memory and Recurrect Neural Network"
author: "580 Group Project (YJ,JY,BL,YG)"
date: "2022/5/7"
output: pdf_document
---

```{r}
library(tidyverse)
library(tidyquant)
library(magrittr)
library(keras)
library(tensorflow)
library(zoo)
library(caret)
```

The plot of close price vs. date. Then, use the ‘min-max scaler’to normalize the Tesla stock price data. Scaled_x = (x-lagged_min(x))/(lagged_max(x) –lagged_min(x)).
Also report the values of the last 5 scaled close prices.
```{r}
data <- read.csv('~/Desktop/Spring 2022/AMS 580/580 group proj/TSLA.csv', header = T) # take TSLA data as an example
# transform the data type from 'chr' to 'Date'
data$Date = as.Date(data$Date)

# visualize our dataset
knitr::kable(head(data))
ggplot(data, aes(x=Date, y = Close)) + geom_line()

# normalize the stock price by using the 'min-max scaler'
data$min_lagged = lag(data$Low)
data$max_lagged = lag(data$High)
data$Close_norm = (data$Close - data$min_lagged) / (data$max_lagged - data$min_lagged)
model_data = matrix(data$Close_norm[-1])
knitr::kable(tail(model_data,5))
```

Divide the cleaned dataset into 570 days of training set, and the last 10 for testing and the rest for training.
```{r}
test_size = 10
train_data = head(model_data,-test_size)
test_data = tail(model_data, test_size)
cat(dim(train_data)[1], 'days are divided into the training set and', dim(test_data)[1], 'days are divided into the testing set.')
```

Here are matrices for training and testing predictors and response in the 3D form, and their dimensions.
```{r}
prediction = 5
lag = prediction
# Training X
# we lag the data 5 times and arrange that into columns
train_X = t(sapply(
    1:(length(train_data) - lag - prediction + 1),
    function(x) train_data[x:(x + lag - 1), 1]
  ))
# now we transform it into 3D form
train_X <- array(
    data = as.numeric(unlist(train_X)),
    dim = c(
        nrow(train_X),
        lag,
        1
    )
)
# Training y
train_y <- t(sapply(
    (1 + lag):(length(train_data) - prediction + 1),
    function(x) train_data[x:(x + prediction - 1)]
))
train_y <- array(
    data = as.numeric(unlist(train_y)),
    dim = c(
        nrow(train_y),
        prediction,
        1
    )
)
# Testing X
test_X = t(sapply(
    1:(length(test_data) - lag - prediction + 1),
    function(x) test_data[x:(x + lag - 1), 1]
  ))
test_X <- array(
    data = as.numeric(unlist(test_X)),
    dim = c(
        nrow(test_X),
        lag,
        1
    )
)
# Testing y
test_y <- t(sapply(
    (1 + lag):(length(test_data) - prediction + 1),
    function(x) test_data[x:(x + prediction - 1)]
))
test_y <- array(
    data = as.numeric(unlist(test_y)),
    dim = c(
        nrow(test_y),
        prediction,
        1
    )
)
dim(train_X)
dim(train_y)
dim(test_X)
dim(test_y)
```

LSTM:
First of all, build the predictive model to predict 5-days stock close price using the training data
and the LSTM method with only one LSTM layer with 200 hidden units, and the loss function of ‘mse’. 
Also make predictions on the last 5 observations by using the first 5 in the testing dataset and compute the Test MSE using the testing data. 
At last, Scale the predicted stock price back and plot the 5-days predictions and the true stock close price in the same figure.
```{r}
#set_random_seed(123)
model <- keras_model_sequential()
model %>%
  layer_lstm(units = 200, input_shape = dim(train_X)[2:3])
model %>%
  layer_dense(units = dim(test_y)[2])

summary(model)
model %>% compile(loss = 'mse',
                  optimizer = 'adam',
                  metrics = 'mse')
history <- model %>% fit(
  x = train_X,
  y = train_y,
  batch_size =16,
  epochs = 50,
  validation_split = 0.1,
  shuffle = FALSE
)

preds_norm = t(predict(model, test_X))
preds_complete = cbind(preds_norm, tail(data, prediction))
preds = preds_complete$preds_norm*(preds_complete$max_lagged - preds_complete$min_lagged) + preds_complete$min_lagged
predictions = data.frame(predictions = preds, true = preds_complete$Close, date = preds_complete$Date)
# Test MSE
(MSE.lstm = RMSE(predictions$true, predictions$predictions)^2)

# Plot
ggplot(data = predictions, aes(x = date)) +
  geom_line(aes(y = predictions, color = 'predictions')) +
  geom_line(aes(y = true, color = 'true'))
```

RNN:
First of all, build the predictive model to predict 5-days stock close price using the training data
and the RNN method with only one RNN layer with 200 hidden units, and the loss function of ‘mse’.
Also make predictions on the last 5 observations by using the first 5 in the testing dataset and compute the Test MSE using the testing data. 
At last, Scale the predicted stock price back and plot the 5-days predictions and the true stock close price in the same figure.
```{r}
#set_random_seed(123)
model <- keras_model_sequential()
model %>%
  layer_simple_rnn(units = 200, input_shape = dim(train_X)[2:3])
model %>%
  layer_dense(units = dim(test_y)[2])

summary(model)
model %>% compile(loss = 'mse',
                  optimizer = 'adam',
                  metrics = c('mse'))
history <- model %>% fit(
  x = train_X,
  y = train_y,
  batch_size =16,
  epochs = 50,
  validation_split = 0.1,
  shuffle = FALSE
)

preds_norm = t(predict(model, test_X))
preds_complete = cbind(preds_norm, tail(data, prediction))
preds = preds_complete$preds_norm*(preds_complete$max_lagged - preds_complete$min_lagged) + preds_complete$min_lagged
predictions = data.frame(predictions = preds, true = preds_complete$Close, date = preds_complete$Date)
# Test MSE
(MSE.rnn = RMSE(predictions$true, predictions$predictions)^2)

# Plot
ggplot(data = predictions, aes(x = date)) +
  geom_line(aes(y = predictions, color = 'predictions')) +
  geom_line(aes(y = true, color = 'true'))
```

Test MSE of LSTM and RNN:
```{r}
MSE.lstm
MSE.rnn
```